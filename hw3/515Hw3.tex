\documentclass[11pt]{amsart}
\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   % ... or a4paper or a5paper or ... 
%\geometry{landscape}                % Activate for for rotated page geometry
\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage[all]{xy}
\usepackage{epstopdf}
\usepackage{color}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}


% these packages make it easy to include figures in the text. 
\usepackage{float}
\restylefloat{figure}
% newcommand
\newcommand{\ip}[1]{\left\langle #1\right\rangle}



\begin{document}
{\Large Name: Philip Pham}  \\
\begin{center}
\Large AMATH 515 \hskip 2in Homework Set 3\\
{\bf Due: Monday, March 9th by midnight.}. 
\end{center}
\bigskip
\begin{enumerate}

\item  Compute the conjugates of the following functions.  
\begin{enumerate}
\item $f(x) = \delta_{\mathbb{B}_{\infty}}(x)$.
  \begin{proof}
    We have that
    \begin{equation*}
      \boxed{
        f^\star(x) =
        \delta^\star_{\mathbb{B}_{\infty}}(x)
        = \max_{y \in \mathbb{B}_{\infty}} \left\langle x, y \right\rangle.}
    \end{equation*}

    By definition,
    \begin{equation*}
      f^\star(x) = \sup_{y}\left\{\left\langle x, y \right\rangle - f(y)\right\}.           
    \end{equation*}
    If $y \not\in \mathbb{B}_{\infty}$, then
    $\left\langle x, y \right\rangle - f(y) = -\infty$ for all $x$. For
    $y \in \mathbb{B}_{\infty}$,
    $\left\langle x, y \right\rangle - f(y) = \left\langle x, y \right\rangle$,
    so to maximize $\left\langle x, y \right\rangle - f(y)$, we should choose
    $y$ such that $\left\langle x, y \right\rangle$ is maximized.
  \end{proof}
\item $f(x) = \delta_{\mathbb{B}_{2}}(x)$.
  \begin{proof}
    We have that
    \begin{equation*}
      \boxed{
        f^\star(x) =
        \delta^\star_{\mathbb{B}_{2}}(x)
        = \max_{y \in \mathbb{B}_{2}} \left\langle x, y \right\rangle.}
    \end{equation*}
    
    The proof is identical to the previous one with $\mathbb{B}_{\infty}$
    replaced by $\mathbb{B}_2$.
  \end{proof}
\item $f(x) = \exp(x)$.
  \begin{proof}
    We have that
    \begin{equation*}
      \boxed{f^\star(x) =
        \begin{cases}
          x\log x - x = x\left(\log x - 1\right), &x > 0; \\
          0, &x = 0; \\
          \infty, &x < 0.
        \end{cases}}
    \end{equation*}

    To see this, we can maximize
    $\left\langle x, y \right\rangle - \exp\left(y\right)$ with respect to $y$
    by taking the derivative, setting it to $0$, and solving for $y$. In doing
    so, we find that $y = \log x$, which is only defined when $x > 0$. When
    $x \leq 0$, we see that we can maximize $xy - \exp\left(y\right)$ by sending
    $y$ to $-\infty$.
  \end{proof}
\item $f(x) =  \log(1+\exp(x))$
  \begin{proof}
    We have that
    \begin{equation*}
      \boxed{f^\star(x) =
        \begin{cases}
          \infty, &x > 1; \\
          0, &x = 1; \\
          x\left(\log x - \log\left(1 - x\right)\right)  + \log\left(1 - x\right), & 0 < x < 1; \\
          0, & x = 0; \\
          \infty, &x < 0.
        \end{cases}}
    \end{equation*}

    Consider $xy - \log(1+\exp(y))$. The derivative with respect to $y$ is
    $x - \frac{\exp(y)}{1+\exp(y)}$. When $x \in \left(0, 1\right)$, we can
    solve for $y = \log\left(\frac{x}{1 - x}\right)$. When $x \geq 1$, the
    derivative is always positive, so we have that the max is obtained when
    $y \rightarrow \infty$. We note that
    \begin{equation*}
      xy - \log(1+\exp(y)) = xy - \left[
        y + \exp(-y) - \frac{\exp(-2y)}{2} + \frac{\exp(-3y)}{3} - \frac{\exp(-4y)}{4} + \cdots
      \right]
    \end{equation*}
    by a Taylor series expansion, so as $y \rightarrow \infty$, we have $\infty$
    if $x > 1$ and $0$ if $x = 1$.

    When $x \leq 0$, the derivative is always negative, so we maximize the
    expression with $y \rightarrow -\infty$. When $x = 0$, only the second term
    remains, so we have $0$. If $x < 0$, we have that the first term tends to
    $\infty$ and the second term tends to $0$.        
  \end{proof}
\item $f(x) = x\log(x)$
\end{enumerate}


\bigskip\bigskip



\item  Let $g$ be any convex function; $f$ is formed using $g$.
Compute $f^*$ in terms of $g^*$.  
\begin{enumerate}
\item $f(x) = \lambda g(x)$.
\item $f(x) = g(x-a) + \langle x, b \rangle$.
\item $f(x) = \inf_z \left\{g(x,z)\right\}$. 
\item $f(x) = \inf_z \left\{\frac{1}{2}\|x-z\|^2 + g(z)\right\}$
\end{enumerate}

\bigskip\bigskip

\item Moreau Identities.
\begin{enumerate}
\item  Derive the Moreau Identity: 
\[
\mbox{prox}_{f}(z) + \mbox{prox}_{f^*}(z) = z. 
\]
You may find the `Fenchel flip' useful. 

\bigskip \bigskip

%\item Take a look at this more detailed identity:  
%\[
%\mbox{prox}_{\alpha f}(z) = z - \alpha \mbox{prox}_{\frac{1}{\alpha}f^*}(z/\alpha).
%\]
%Don't prove this, but please remember it --- its very useful for coding. 

\bigskip \bigskip

\item Use either of the Moreau identities and 
1a, 1b to check your formulas for 
\[
\mbox{prox}_{\|\cdot\|_1}, \quad \mbox{prox}_{\|\cdot\|_2}
\]
from last week's homework. 
\end{enumerate}



%\item Consider the following linear program: 
%\[
%\min_x c^Tx \quad \mbox{s.t.} \quad Ax \leq b, \quad x \geq 0.
%\] 
%Derive the dual problem we get from the perturbation 
%\[
%p(u) = \min_{x} c^Tx \quad \mbox{s.t.} \quad Ax \leq b + u, \quad x \geq 0.
%\]

%\bigskip\bigskip\bigskip

%\item{Duals of Lasso Formulations}
%
%\begin{enumerate}
%
%\item Compute the dual of  the constrained Lasso problem
%\[
%\min_{x} \frac{1}{2}\|b - Ax\|^2 \quad \mbox {s.t.} \quad \|x\|_1 \leq \tau. 
%\]
%obtained from the perturbation 
%\[
%p(u) = \min_{x} \frac{1}{2}\|b - Ax + u\|^2 \quad \mbox {s.t.} \quad \|x\|_1 \leq \tau. 
%\]
%
%\bigskip\bigskip
%
%\item Compute the dual for the modified problem  
%\[
%\min_{x} \|b - Ax\|_2 +\lambda \|x\|_1. 
%\]
%obtained from perturbation 
%\[
%p(u) = \min_{x} \|b - Ax + u\|_2 +\lambda \|x\|_1. 
%\]
%
%
%\end{enumerate}
%
%\bigskip\bigskip\bigskip

\item Duals of regularized GLM. Consider the Generalized Linear Model family: 
\[
\min_{x} \sum_{i=1}^n g(\langle a_i, x\rangle) - b^TAx + R(x),
\]
Where $g$ is convex and $R$ is any regularizer. 
\begin{enumerate}
\item Write down the general dual obtained from the perturbation 
\[
p(u) = \min_{x} \sum_{i=1}^n g(\langle a_i, x\rangle + u_i) - b^TAx + R(x).
\]
\bigskip\bigskip
\item Specify your formula to Ridge-regularized logistic regression: 
\[
\min_x \sum_{i=1}^n \log(1+\exp(\langle a_i, x \rangle))  - b^TAx  + \frac{\lambda}{2}\|x\|^2. 
\]
\bigskip\bigskip
\item Specify your formula to 1-norm regularized Poisson regression: 
\[
\min_x \sum_{i=1}^n \exp(\langle a_i, x \rangle) - b^TAx +  \lambda\|x\|_1. 
\]
\end{enumerate}
\bigskip \bigskip
\end{enumerate}
\noindent{\bf Coding Assignment}
\vskip 8pt
Please download \texttt{515Hw3\_Coding.ipynb} and \texttt{proxes.py} to complete problem (5).

\vskip 16pt
\begin{enumerate}
\item[(5)] In this problem you will write a routine to project onto the capped simplex. 

The Capped Simplex $\Delta_k$ is defined as follows: 
\[
\Delta_k := \left\{x: 1^Tx = k, \quad 0 \leq x_i \leq 1 \quad \forall i. \right\}
\]
This is the intersection of the $k$-simplex with the unit box. 

The projection problem is given by 
\[
\mbox{proj}_{\Delta_k}(z) = \arg\min_{x \in \Delta_k} \frac{1}{2}\|x-z\|^2.
\]
\begin{enumerate}
\item Derive the (1-dimensional) dual problem by focusing on the $1^Tx = k$ constraint. 
\bigskip \bigskip
\item Implement a routine to solve this dual. It's a scalar root finding problem, 
so you can use the root-finding algorithm provided in the code.  
\bigskip \bigskip
\item Using the dual solution, write down a closed form formula for the projection.  
Use this formula, along with your dual solver, to implement the projection. You can use the unit test 
provided to check if your code id working correctly. 


\end{enumerate}




\end{enumerate}


\end{document}  
